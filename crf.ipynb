{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"C:\\\\Users\\\\mvy48\\\\Downloads\\\\ml_combined_anoop-cc-gokul_07Dec19.txt\"\n",
    "with open(dataset_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    dataset = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 200000 of 200000\r"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset\n",
    "sentences = []\n",
    "for i, text in enumerate(dataset):\n",
    "    print(\"Document \" + str(i + 1) + \" of \" + str(len(dataset)), end=\"\\r\", flush=True)\n",
    "    # Convert text to lowercase and remove leading/trailing whitespaces\n",
    "    prepared_text = text.strip().lower()\n",
    "    # Remove non-alphabetic characters except spaces\n",
    "    prepared_text = \"\".join([c if c.isalpha() or c.isspace() else \"\" for c in prepared_text])\n",
    "    sentences.append(prepared_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove very short sentences\n",
    "sentences = [s for s in sentences if len(s) > 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('അ', 0), ('വ', 0), ('ഹ', 0), ('ത', 0), ('ബ', 1), ('ന', 0), ('ധ', 0), ('ത', 0), ('ത', 0), ('ല', 0), ('അ', 1), ('സ', 0), ('വ', 0), ('ര', 0), ('സ', 0), ('യ', 0), ('ങ', 0), ('ങ', 0), ('ള', 0), ('ണ', 0), ('ശ', 1), ('ല', 0), ('ജ', 0), ('ത', 1), ('ര', 0), ('വ', 0), ('ദ', 0), ('യ', 0), ('ട', 0), ('ദ', 1), ('ര', 0), ('ണ', 0), ('മ', 0), ('യ', 0), ('ക', 1), ('ല', 0), ('പ', 0), ('ത', 0), ('ക', 0), ('ത', 0), ('ത', 0), ('ന', 0), ('ക', 1), ('ര', 0), ('ണ', 0), ('മ', 0), ('യ', 0), ('ത', 0)]\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "prepared_sentences = []\n",
    "for sentence in sentences:\n",
    "    # Calculate the positions of word boundaries\n",
    "    lengths = [len(w) for w in sentence.split(\" \")]\n",
    "    positions = []\n",
    "    next_pos = 0\n",
    "    for length in lengths:\n",
    "        next_pos = next_pos + length\n",
    "        positions.append(next_pos)\n",
    "    # Concatenate the sentence and remove spaces\n",
    "    concatenated = sentence.replace(\" \", \"\")\n",
    "    # Create lists of characters and labels\n",
    "    chars = [c for c in concatenated]\n",
    "    labels = [0 if not i in positions else 1 for i, c in enumerate(concatenated)]\n",
    "    prepared_sentences.append(list(zip(chars, labels)))\n",
    "print([d for d in prepared_sentences[100]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to create features and labels\n",
    "def create_char_features(sentence, i):\n",
    "    features = [\n",
    "        'bias',\n",
    "        'char=' + sentence[i][0] \n",
    "    ]\n",
    "    if i >= 1:\n",
    "        features.extend([\n",
    "            'char-1=' + sentence[i-1][0],\n",
    "            'char-1:0=' + sentence[i-1][0] + sentence[i][0],\n",
    "        ])\n",
    "    else:\n",
    "        features.append(\"BOS\")\n",
    "    if i >= 2:\n",
    "        features.extend([\n",
    "            'char-2=' + sentence[i-2][0],\n",
    "            'char-2:0=' + sentence[i-2][0] + sentence[i-1][0] + sentence[i][0],\n",
    "            'char-2:-1=' + sentence[i-2][0] + sentence[i-1][0],\n",
    "        ])\n",
    "    if i >= 3:\n",
    "        features.extend([\n",
    "            'char-3:0=' + sentence[i-3][0] + sentence[i-2][0] + sentence[i-1][0] + sentence[i][0],\n",
    "            'char-3:-1=' + sentence[i-3][0] + sentence[i-2][0] + sentence[i-1][0],\n",
    "        ])\n",
    "    if i + 1 < len(sentence):\n",
    "        features.extend([\n",
    "            'char+1=' + sentence[i+1][0],\n",
    "            'char:+1=' + sentence[i][0] + sentence[i+1][0],\n",
    "        ])\n",
    "    else:\n",
    "        features.append(\"EOS\")\n",
    "    if i + 2 < len(sentence):\n",
    "        features.extend([\n",
    "            'char+2=' + sentence[i+2][0],\n",
    "            'char:+2=' + sentence[i][0] + sentence[i+1][0] + sentence[i+2][0],\n",
    "            'char+1:+2=' + sentence[i+1][0] + sentence[i+2][0],\n",
    "        ])\n",
    "    if i + 3 < len(sentence):\n",
    "        features.extend([\n",
    "            'char:+3=' + sentence[i][0] + sentence[i+1][0] + sentence[i+2][0]+ sentence[i+3][0],\n",
    "            'char+1:+3=' + sentence[i+1][0] + sentence[i+2][0] + sentence[i+3][0],\n",
    "        ])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_features(prepared_sentence):\n",
    "    return [create_char_features(prepared_sentence, i) for i in range(len(prepared_sentence))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_labels(prepared_sentence):\n",
    "    return [str(part[1]) for part in prepared_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and labels for training data\n",
    "X = [create_sentence_features(ps) for ps in prepared_sentences]\n",
    "y = [create_sentence_labels(ps)   for ps in prepared_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(0.7 * len(X))\n",
    "X_train = X[:split_index]\n",
    "y_train = y[:split_index]\n",
    "X_test = X[split_index:]\n",
    "y_test = y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a CRF model\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "trainer.set_params({\n",
    "    'c1': 1.0, \n",
    "    'c2': 1e-3,\n",
    "    'max_iterations': 60,\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "trainer.train('trained_model.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x1c639914950>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the trained model\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('trained_model.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "മകന ുവേണ്ടി അച്ഛന ുംപ്രമുഖന ിർമ്മാതാവുമായ എഎൽ അളഗ പ്പനാണ്വിവാഹംനടത്താൻതീരുമാനിച്ചിരിക്കുന്നത് എന്നാണ്സൂചന.\n",
      "ഇന്ന്റായ്ബറേലിയി ൽകോൺഗ്രസ് ഉപാദ്ധ്യക്ഷൻ രാഹു ൽഗാന്ധിയുടെരണ്ട്റാലികളി ൽപ്രിയങ്കഗാന്ധിയുംപങ്കെടുക്കും.\n",
      "എന്നാ ൽരണ്ടുമാസത്തിനകം ഭരണഘടനാകോടതി അദ്ദേഹത്തെപ്രസിഡൻറ ്പദത്തി ൽവീണ്ടും അവര ോധിച്ചു.\n",
      "വിവോ ഇന്ത്യപ്രീമിയർലീഗി ൽ ഔദ്യോഗികപാർട്ണറായിരുന്നുടാറ്റാനെക്സോൺ.\n",
      "വലിയൊരുസ്വപ്നംപൊലി ഞ്ഞതി ൽസങ് കടമൊക്കെയുണ്ടായെങ്കിലും അത്മുഹമ് മദ്താലിഫ് എന്നപന്ത്രണ്ടുകാരനെപ്രസിദ്ധനാക്കിയിരിക്കുകയാണ്.\n",
      "ഏറെനാളത്തെപ്രണയത്തിന്ശേഷമാണ് മലയാളികളുടെപ്രിയനടിഭാവനയുംകന്ന ഡസിനിമാനിർമാതാവ്നവീനുംവിവാഹിതരാകാൻ പോകുന്നത്.\n",
      "മൂന്നാംവിക്കറ്റി ൽരോഹിത്-റായിഡുസഖ്യംകൂട്ടിച്ചേർച്ച# റൺസ ാണ് ഇന്ത്യൻ ഇന്നിംഗ്സിന്റെനട്ടെല്ല്.\n",
      "എന്നെപ്പോലെതന്നെ അവര ുംവിശന്നുകൊണ്ടായിരിക്കും ഉറങ ്ങാൻ പോകുന്നത് എന്നെല്ലാംഞാൻ ചിന്തിച്ചിരുന്നു.\n",
      "ആറ്മുതൽ ഒൻപത്സീറ്റുകൾ വരെയുള്ള ഒര ുചെറിയവിമാനം ചാർട ്ടർ ചെയ്ത് പറക്കാൻമണിക്കൂറിന് ഒന്നരലക്ഷംമുതൽ രണ്ട്ലക്ഷംവരെയാണ് ഇപ്പോൾ ചെലവ്വരുന്നത്.\n",
      "ഇതേതുടർന്ന്ഡിജിപിയുംമന്ത്രി കടകംപള്ളിസുരേന്ദ്രനുംമാധ്യമങ്ങൾ ക്ക്വിലക്കില്ലെന്നുംസുരക്ഷയൊരുക്കുന്നതിൻറ െഭാഗമായ നടപടിമാത്രമാണ്നടക്കുന്നതെന്നുംവിശദീകരിച്ചിരുന്നു.\n",
      "വിശദീകരിക്കുന്ന എല്ലാംതന്റെനിരവധ ിസന്ദർഭങ്ങളി ൽപ്രയ ോഗിക്കുന്നതിനായിഞാൻസന്തുലിതമാണ്\n"
     ]
    }
   ],
   "source": [
    "def segment_sentence(sentence):\n",
    "    sent = sentence.replace(\" \", \"\")\n",
    "    prediction = tagger.tag(create_sentence_features(sent))\n",
    "    complete = \"\"\n",
    "    for i, p in enumerate(prediction):\n",
    "        if p == \"1\":\n",
    "            complete += \" \" + sent[i]\n",
    "        else:\n",
    "            complete += sent[i]\n",
    "    return complete\n",
    "print(segment_sentence(\"മകനുവേണ്ടിഅച്ഛനുംപ്രമുഖനിർമ്മാതാവുമായഎഎൽഅളഗപ്പനാണ്വിവാഹംനടത്താൻതീരുമാനിച്ചിരിക്കുന്നത്എന്നാണ്സൂചന.\"))\n",
    "print(segment_sentence(\"ഇന്ന്റായ്ബറേലിയിൽകോൺഗ്രസ്ഉപാദ്ധ്യക്ഷൻരാഹുൽഗാന്ധിയുടെരണ്ട്റാലികളിൽപ്രിയങ്കഗാന്ധിയുംപങ്കെടുക്കും.\"))\n",
    "print(segment_sentence(\"എന്നാൽരണ്ടുമാസത്തിനകംഭരണഘടനാകോടതിഅദ്ദേഹത്തെപ്രസിഡൻറ്പദത്തിൽവീണ്ടുംഅവരോധിച്ചു.\"))\n",
    "print(segment_sentence(\"വിവോഇന്ത്യപ്രീമിയർലീഗിൽഔദ്യോഗികപാർട്ണറായിരുന്നുടാറ്റാനെക്സോൺ.\"))\n",
    "print(segment_sentence(\"വലിയൊരുസ്വപ്നംപൊലിഞ്ഞതിൽസങ്കടമൊക്കെയുണ്ടായെങ്കിലുംഅത്മുഹമ്മദ്താലിഫ്എന്നപന്ത്രണ്ടുകാരനെപ്രസിദ്ധനാക്കിയിരിക്കുകയാണ്.\"))\n",
    "print(segment_sentence(\"ഏറെനാളത്തെപ്രണയത്തിന്ശേഷമാണ്മലയാളികളുടെപ്രിയനടിഭാവനയുംകന്നഡസിനിമാനിർമാതാവ്നവീനുംവിവാഹിതരാകാൻപോകുന്നത്.\"))\n",
    "print(segment_sentence(\"മൂന്നാംവിക്കറ്റിൽരോഹിത്-റായിഡുസഖ്യംകൂട്ടിച്ചേർച്ച#റൺസാണ്ഇന്ത്യൻഇന്നിംഗ്സിന്റെനട്ടെല്ല്.\"))\n",
    "print(segment_sentence(\"എന്നെപ്പോലെതന്നെഅവരുംവിശന്നുകൊണ്ടായിരിക്കുംഉറങ്ങാൻപോകുന്നത്എന്നെല്ലാംഞാൻചിന്തിച്ചിരുന്നു.\"))\n",
    "print(segment_sentence(\"ആറ്മുതൽഒൻപത്സീറ്റുകൾവരെയുള്ളഒരുചെറിയവിമാനംചാർട്ടർചെയ്ത്പറക്കാൻമണിക്കൂറിന്ഒന്നരലക്ഷംമുതൽരണ്ട്ലക്ഷംവരെയാണ്ഇപ്പോൾചെലവ്വരുന്നത്.\"))\n",
    "print(segment_sentence(\"ഇതേതുടർന്ന്ഡിജിപിയുംമന്ത്രികടകംപള്ളിസുരേന്ദ്രനുംമാധ്യമങ്ങൾക്ക്വിലക്കില്ലെന്നുംസുരക്ഷയൊരുക്കുന്നതിൻറെഭാഗമായനടപടിമാത്രമാണ്നടക്കുന്നതെന്നുംവിശദീകരിച്ചിരുന്നു.\"))\n",
    "print(segment_sentence(\"വിശദീകരിക്കുന്നഎല്ലാംതന്റെനിരവധിസന്ദർഭങ്ങളിൽപ്രയോഗിക്കുന്നതിനായിഞാൻസന്തുലിതമാണ്\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "n_correct = 0\n",
    "n_incorrect = 0\n",
    "for i in range(len(X_test)):\n",
    "    prediction = tagger.tag(X_test[i])\n",
    "    correct = y_test[i]\n",
    "    zipped = list(zip(prediction, correct))\n",
    "    tp += len([_ for l, c in zipped if l == c and l == \"1\"])\n",
    "    fp += len([_ for l, c in zipped if l == \"1\" and c == \"0\"])\n",
    "    fn += len([_ for l, c in zipped if l == \"0\" and c == \"1\"])\n",
    "    n_incorrect += len([_ for l, c in zipped if l != c])\n",
    "    n_correct += len([_ for l, c in zipped if l == c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:\t0.9396259398556203\n",
      "Recall:\t\t0.9302941822069429\n",
      "Accuracy:\t0.976900621369989\n",
      "F1 score:\t0.9349367761594344\n"
     ]
    }
   ],
   "source": [
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "accuracy = n_correct / (n_correct + n_incorrect)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Precision:\\t\" + str(precision))\n",
    "print(\"Recall:\\t\\t\" + str(recall))\n",
    "print(\"Accuracy:\\t\" + str(accuracy))\n",
    "print(\"F1 score:\\t\" + str(f1_score))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
